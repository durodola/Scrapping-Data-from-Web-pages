{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Web_Scrapping_yaoundezoom.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDkH6OvcF7dB",
        "colab_type": "text"
      },
      "source": [
        "# Scrapping Data from http://www.yaoundezoom.com/ Website \n",
        "Date: 17/09/2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsFqg0CSQwW2",
        "colab_type": "text"
      },
      "source": [
        "# A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPwUDmMnQtnU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "outputId": "beccd195-06b9-4fd8-8801-f7eb80bf6897"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urla = \"http://www.yaoundezoom.com/web/fr/activite/alpha/A\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urla)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      #name_tag = job_soup.find('div',{'class':'div_titre_show_activite'})\n",
        "      #name = name_tag.text if name_tag else \"N/A\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    #url_tag = url_tag.find('a').get('href')\n",
        "    if url_tag:\n",
        "        urla= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urla)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "# To save in CSV\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=5\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=6\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=7\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=8\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=9\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=10\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=11\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=12\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=13\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=14\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=15\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=16\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=17\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=18\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=19\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=20\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=21\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=22\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=23\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=24\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=25\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=26\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=27\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/A?page=28\n",
            "Total Jobs: 697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comp_Name</th>\n",
              "      <th>Info</th>\n",
              "      <th>Activities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A &amp; T Distribution Sarl</td>\n",
              "      <td>\\nContactez A &amp; t distribution sarl\\n \\n\\n  \\n...</td>\n",
              "      <td>\\nSecteur d'activité: Alcools, vins, spiritueu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A A M Communication</td>\n",
              "      <td>\\nContactez A a m communication\\n \\n\\n  \\n\\t\\t...</td>\n",
              "      <td>\\nSecteur d'activité: Mobilier de maison - mob...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A B Motors Cameroun Sarl</td>\n",
              "      <td>\\nContactez A b motors cameroun sarl\\n \\n\\n  \\...</td>\n",
              "      <td>\\nSecteur d'activité: Mobilier de maison - mob...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A Corps Parfait</td>\n",
              "      <td>\\nContactez A corps parfait\\n \\n\\n  \\n\\t\\t\\tTé...</td>\n",
              "      <td>\\nSecteur d'activité: Salon de coiffure - esth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A Samy Telecom</td>\n",
              "      <td>\\nContactez A samy telecom\\n \\n\\n  \\n\\t\\t\\tTél...</td>\n",
              "      <td>\\nSecteur d'activité: Télécommunication - télé...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Comp_Name  ...                                         Activities\n",
              "1   A & T Distribution Sarl  ...  \\nSecteur d'activité: Alcools, vins, spiritueu...\n",
              "2       A A M Communication  ...  \\nSecteur d'activité: Mobilier de maison - mob...\n",
              "3  A B Motors Cameroun Sarl  ...  \\nSecteur d'activité: Mobilier de maison - mob...\n",
              "4           A Corps Parfait  ...  \\nSecteur d'activité: Salon de coiffure - esth...\n",
              "5            A Samy Telecom  ...  \\nSecteur d'activité: Télécommunication - télé...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KviLrwbHQtuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "npo_jobs_df.to_csv('yaoundezoom_Atest.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqSIlsEvQ1bp",
        "colab_type": "text"
      },
      "source": [
        "# B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO-4FVgAQt5k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "b52d9458-c9a7-47b9-ec0e-3d50663d21da"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlb = \"http://www.yaoundezoom.com/web/fr/activite/alpha/B\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlb)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlb= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlb)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_B.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/B?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/B?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/B?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/B?page=5\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/B?page=6\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/B?page=7\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/B?page=8\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/B?page=9\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/B?page=10\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/B?page=11\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/B?page=12\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/B?page=13\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/B?page=14\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/B?page=15\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/B?page=16\n",
            "Total Jobs: 378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlfkNlHoQuFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Buheb6ZpQ32i",
        "colab_type": "text"
      },
      "source": [
        "# C"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuQzppnhQuAv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "outputId": "90d66fd5-9907-4ee4-c874-f7cba3498205"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlc = \"http://www.yaoundezoom.com/web/fr/activite/alpha/C\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlc)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlc= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlc)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_C.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=5\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=6\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=7\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=8\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=9\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=10\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=11\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=12\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=13\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=14\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=15\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=16\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=17\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=18\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=19\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=20\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=21\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=22\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=23\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=24\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=25\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=26\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=27\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=28\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=29\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=30\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=31\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=32\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=33\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=34\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=35\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=36\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=37\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=38\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=39\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=40\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=41\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=42\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=43\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=44\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=45\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=46\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/C?page=47\n",
            "Total Jobs: 1170\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNC6WC7yQ8Mr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnEzVMa0RBHH",
        "colab_type": "text"
      },
      "source": [
        "# D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQuKOGjDQ93f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "04421758-da52-484f-8d65-20b5a2af62ad"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urld = \"http://www.yaoundezoom.com/web/fr/activite/alpha/D\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urld)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urld= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urld)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_D.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/D?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/D?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/D?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/D?page=5\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/D?page=6\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/D?page=7\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/D?page=8\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/D?page=9\n",
            "Total Jobs: 222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m-C40-uRDZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SnU6QThQ-x0",
        "colab_type": "text"
      },
      "source": [
        "# E"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1mn87duQ90_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "a3b36b54-82cd-457e-c30d-f463e7a9eb72"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urle = \"http://www.yaoundezoom.com/web/fr/activite/alpha/E\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urle)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urle= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urle)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_E.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=5\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=6\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=7\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=8\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=9\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=10\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=11\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=12\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=13\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=14\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=15\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=16\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=17\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=18\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=19\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=20\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=21\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/E?page=22\n",
            "Total Jobs: 528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMPAHAB5Q8Jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlC37W06RNMF",
        "colab_type": "text"
      },
      "source": [
        "# F"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9JN1pBpQ8Gl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "e32e47ff-e1ab-4fb6-8301-482d777dcdb4"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlf = \"http://www.yaoundezoom.com/web/fr/activite/alpha/F\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlf)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlf= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlf)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_F.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/F?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/F?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/F?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/F?page=5\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/F?page=6\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/F?page=7\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/F?page=8\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/F?page=9\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/F?page=10\n",
            "Total Jobs: 249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbOxAoOQQt1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmEgwduDrrXk",
        "colab_type": "text"
      },
      "source": [
        "# G"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7NKnE97nKEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpMHG5j5rxKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "ee5aa60e-b55c-4310-b1b6-981568c3ee81"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlg = \"http://www.yaoundezoom.com/web/fr/activite/alpha/G\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlg)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlg= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlg)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_G.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=5\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=6\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=7\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=8\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=9\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=10\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=11\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=12\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=13\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=14\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=15\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=16\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=17\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=18\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=19\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=20\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=21\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/G?page=22\n",
            "Total Jobs: 534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en7NORw8rxNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ8MOYzCrxXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRQUAzRbsITM",
        "colab_type": "text"
      },
      "source": [
        "# H"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrH9ggWArxTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "ec5c6a47-7a99-4050-c1da-6f32a9460f19"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlh = \"http://www.yaoundezoom.com/web/fr/activite/alpha/H\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlh)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlh= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlh)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_H.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/H?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/H?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/H?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/H?page=5\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/H?page=6\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/H?page=7\n",
            "Total Jobs: 167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7N0b_xWtElt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq7ltu1HsO-n",
        "colab_type": "text"
      },
      "source": [
        "# I"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJy_YrMPuRhN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "91580b80-31f3-485e-de1c-173f195bbda1"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urli = \"http://www.yaoundezoom.com/web/fr/activite/alpha/I\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urli)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urli= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urli)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_I.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/I?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/I?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/I?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/I?page=5\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/I?page=6\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/I?page=7\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/I?page=8\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/I?page=9\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/I?page=10\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/I?page=11\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/I?page=12\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/I?page=13\n",
            "Total Jobs: 316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FouseiE5uRnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MTEQYlJsPbz",
        "colab_type": "text"
      },
      "source": [
        "# J"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNwCq0tYuf3b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "016eefee-d843-44f7-ce06-42ecd25e3ce8"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlj = \"http://www.yaoundezoom.com/web/fr/activite/alpha/J\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlj)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlj= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlj)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_J.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/J?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/J?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/J?page=4\n",
            "Total Jobs: 82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jcjn19-pugCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFwkTHrHsPxK",
        "colab_type": "text"
      },
      "source": [
        "# K"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGhEP9oCu0y5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "0b05df5c-66e3-41ef-dd3b-c1e42eb614a0"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlk = \"http://www.yaoundezoom.com/web/fr/activite/alpha/K\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlk)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlk= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlk)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_K.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/K?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/K?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/K?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/K?page=5\n",
            "Total Jobs: 109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I79r5sXdu05h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzZWRFlfsP8m",
        "colab_type": "text"
      },
      "source": [
        "# L"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXEJjZaH7kL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "e10be782-a37e-4ec1-8cf3-0510a2622036"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urll = \"http://www.yaoundezoom.com/web/fr/activite/alpha/L\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urll)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urll= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urll)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_L.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/L?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/L?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/L?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/L?page=5\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/L?page=6\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/L?page=7\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/L?page=8\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/L?page=9\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/L?page=10\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/L?page=11\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/L?page=12\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/L?page=13\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/L?page=14\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/L?page=15\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/L?page=16\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/L?page=17\n",
            "Total Jobs: 402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOSKEt6T7kQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzxmd5nrsQBl",
        "colab_type": "text"
      },
      "source": [
        "# M"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCabY97k7wLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "4f1c7e24-33b9-4569-a941-8035a7858c1c"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlm = \"http://www.yaoundezoom.com/web/fr/activite/alpha/M\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlm)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlm= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlm)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_M.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=5\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=6\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=7\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=8\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=9\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=10\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=11\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=12\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=13\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=14\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=15\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=16\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=17\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=18\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=19\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=20\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=21\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=22\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=23\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/M?page=24\n",
            "Total Jobs: 598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdp6k1l17xWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jlm4JD4nsQPE",
        "colab_type": "text"
      },
      "source": [
        "# N"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zAeTMtB8Dah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "cf319b14-573d-429d-b220-03a3733a3eea"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urln = \"http://www.yaoundezoom.com/web/fr/activite/alpha/N\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urln)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urln= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urln)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_N.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/N?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/N?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/N?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/N?page=5\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/N?page=6\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/N?page=7\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/N?page=8\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/N?page=9\n",
            "Total Jobs: 205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBDzmp6g8DeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcZm3jeFsQdi",
        "colab_type": "text"
      },
      "source": [
        "# O"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXNSXt2a8Rzd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "c75afd58-0722-4171-ee34-4f77f8badc40"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlo = \"http://www.yaoundezoom.com/web/fr/activite/alpha/O\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlo)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlo= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlo)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_O.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/O?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/O?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/O?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/O?page=5\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/O?page=6\n",
            "Total Jobs: 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkE_HqHK8R9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEy5HYSBsRAd",
        "colab_type": "text"
      },
      "source": [
        "# P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_M2YVXP9L7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "a4ea4a56-6750-4b0f-ee02-53ab3c0d42f2"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlp = \"http://www.yaoundezoom.com/web/fr/activite/alpha/P\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlp)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlp= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlp)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_P.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/P?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/P?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/P?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/P?page=5\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/P?page=6\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/P?page=7\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/P?page=8\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/P?page=9\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/P?page=10\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/P?page=11\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/P?page=12\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/P?page=13\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/P?page=14\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/P?page=15\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/P?page=16\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/P?page=17\n",
            "Total Jobs: 414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzCHo1yw9L_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMqddhKxsRQW",
        "colab_type": "text"
      },
      "source": [
        "# Q"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN4Jdidd9avB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "634aa907-06e1-4672-f965-78e512dc0f13"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlq = \"http://www.yaoundezoom.com/web/fr/activite/alpha/Q\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlq)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlq= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlq)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_Q.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/Q?page=2\n",
            "Total Jobs: 31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCGwyd5I9azc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tylVACzesRY7",
        "colab_type": "text"
      },
      "source": [
        "# R"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBWwhJr29oat",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "114c3921-e193-4e22-8109-ab1f1f2c7fc0"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlr = \"http://www.yaoundezoom.com/web/fr/activite/alpha/R\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlr)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlr= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlr)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_R.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/R?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/R?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/R?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/R?page=5\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/R?page=6\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/R?page=7\n",
            "Total Jobs: 151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x-SxZba9oej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOK0LMrBsRhg",
        "colab_type": "text"
      },
      "source": [
        "# S"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWZvQOxF98Zm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "outputId": "662c7825-32bb-4055-8f8f-f133a62de0c8"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urls = \"http://www.yaoundezoom.com/web/fr/activite/alpha/S\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urls)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urls= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urls)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_S.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=5\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=6\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=7\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=8\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=9\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=10\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=11\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=12\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=13\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=14\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=15\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=16\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=17\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=18\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=19\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=20\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=21\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=22\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=23\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=24\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=25\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=26\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=27\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=28\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=29\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=30\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=31\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=32\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=33\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=34\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=35\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=36\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=37\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=38\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=39\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=40\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=41\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=42\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=43\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=44\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=45\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=46\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=47\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=48\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=49\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/S?page=50\n",
            "Total Jobs: 1241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjxT3aan98dw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX8VlWc0sRrG",
        "colab_type": "text"
      },
      "source": [
        "# T"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH_iay8WrxRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "a18dee1e-5be8-4a69-e3a6-066c64f5998d"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlt = \"http://www.yaoundezoom.com/web/fr/activite/alpha/T\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlt)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlt= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlt)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_T.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/T?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/T?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/T?page=4\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/T?page=5\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/T?page=6\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/T?page=7\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/T?page=8\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/T?page=9\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/T?page=10\n",
            "Total Jobs: 227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reHF05b1-Le-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNb_miIvsrag",
        "colab_type": "text"
      },
      "source": [
        "# U"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtnN1_AZ-ewq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "7b3be975-a363-4efc-a177-9153255f1562"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlu = \"http://www.yaoundezoom.com/web/fr/activite/alpha/U\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlu)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlu= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlu)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_U.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/U?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/U?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/U?page=4\n",
            "Total Jobs: 79\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKTDTQYf-e0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC8hNnJTsskM",
        "colab_type": "text"
      },
      "source": [
        "# V"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-9ue34O-tfr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "ebf9f872-c591-4062-88cf-46723ee4a8af"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlv = \"http://www.yaoundezoom.com/web/fr/activite/alpha/V\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlv)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlv= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlv)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_V.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/V?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/V?page=3\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/V?page=4\n",
            "Total Jobs: 86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTTEucxs-tkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSmrW6zessiN",
        "colab_type": "text"
      },
      "source": [
        "# W"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpugJwy0_I8F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "038d49a4-eaa0-4a5f-f8f4-2ee859cc654e"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlw = \"http://www.yaoundezoom.com/web/fr/activite/alpha/W\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlw)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlw= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlw)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_W.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/W?page=2\n",
            "http://www.yaoundezoom.com/web/fr/activite/alpha/W?page=3\n",
            "Total Jobs: 70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo49S787_JAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVt7R2u7szZm",
        "colab_type": "text"
      },
      "source": [
        "# X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwjCUIC4_rRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "55d8879d-c68f-4a00-dec5-0a80d0c4eb5d"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlx = \"http://www.yaoundezoom.com/web/fr/activite/alpha/X\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlx)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlx= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlx)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_X.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Jobs: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvF-SOOY_rhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI0ewl8ys0Xu",
        "colab_type": "text"
      },
      "source": [
        "# Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5yeCBZQ_-_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b128d6c2-f30c-4c1a-96ba-256dd880ce6c"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urly = \"http://www.yaoundezoom.com/web/fr/activite/alpha/Y\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urly)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urly= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urly)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_Y.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Jobs: 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfyHHZRA__Dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_nBQ6pws0_V",
        "colab_type": "text"
      },
      "source": [
        "# Z"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbeJidERAR5u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "642b1827-67f9-40a6-cb0e-391426c627e4"
      },
      "source": [
        "# Import different packages to use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "urlz = \"http://www.yaoundezoom.com/web/fr/activite/alpha/Z\"\n",
        "\n",
        "npo_jobs = {}\n",
        "job_no = 0\n",
        "while True:\n",
        "    \n",
        "    response = requests.get(urlz)\n",
        "    data = response.text\n",
        "    soup = BeautifulSoup(data,'html.parser')\n",
        "    jobs = soup.find_all('div',{'class':'div_categorielist_detail_btn'})\n",
        "    for job in jobs:\n",
        "      links = job.find('a').get('href')\n",
        "      link = 'http://www.yaoundezoom.com' + links\n",
        "      job_response = requests.get(link)\n",
        "      job_data = job_response.text\n",
        "      job_soup = BeautifulSoup(job_data, 'html.parser')\n",
        "      activities_loca_tag = job_soup.find('div',{'class':'div_intro_cellule01_text'})\n",
        "      activities_loca = activities_loca_tag.text if activities_loca_tag else \"NA\"\n",
        "      comp_name = job_soup.find('h1').text\n",
        "      info_tag = job_soup.find('div',{'class':'div_list_entreprise_zone1-1__activiteshow'})\n",
        "      info = info_tag.text if info_tag else \"NA\"\n",
        "      job_no+=1\n",
        "      npo_jobs[job_no] = [comp_name, info, activities_loca]\n",
        "      #print('Comp_Name: ', comp_name, '\\nInfo', info, '\\nActivities_Loca', activities_loca)\n",
        "    \n",
        "    url_tag = soup.find('span',{'class':'next'})\n",
        "    if url_tag:\n",
        "        urlz= 'http://www.yaoundezoom.com' + url_tag.find('a').get('href')\n",
        "        print(urlz)\n",
        "        time.sleep(2)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total Jobs:\", job_no)\n",
        "\n",
        "# Convert the data into a data frame, DataFrame is a data structure in pyton peculair to pandas\n",
        "npo_jobs_df = pd.DataFrame.from_dict(npo_jobs, orient='index', columns=['Comp_Name','Info', 'Activities'])\n",
        "npo_jobs_df.head()\n",
        "\n",
        "\n",
        "# To save in CSV\n",
        "npo_jobs_df.to_csv('yaoundezoom_Z.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.yaoundezoom.com/web/fr/activite/alpha/Z?page=2\n",
            "Total Jobs: 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WRwoKHqAR2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}